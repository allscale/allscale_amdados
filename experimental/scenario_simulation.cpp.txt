//-----------------------------------------------------------------------------
// Author    : Albert Akhriev, albert_akhriev@ie.ibm.com
//             Fearghal O'Donncha, feardonn@ie.ibm.com
// Copyright : IBM Research Ireland, 2017
//-----------------------------------------------------------------------------

#include "allscale/api/user/data/adaptive_grid.h"
#include "allscale/api/user/algorithm/pfor.h"
#include "allscale/api/user/algorithm/stencil.h"
#include "allscale/api/core/io.h"
#include "allscale/utils/assert.h"
#include "../include/debugging.h"
#include "../include/geometry.h"
#include "../include/amdados_utils.h"
#include "../include/matrix.h"
#include "../include/configuration.h"
#include "../include/cholesky.h"
#include "../include/lu.h"
#include "../include/kalman_filter.h"
#include "../include/demo_average_profile.h"

namespace amdados {

using ::allscale::api::user::algorithm::pfor;
using ::allscale::api::user::data::Grid;
using ::allscale::api::user::data::GridPoint;
using ::allscale::api::user::data::Direction;
using ::allscale::api::user::data::Direction::Up;
using ::allscale::api::user::data::Direction::Down;
using ::allscale::api::user::data::Direction::Left;
using ::allscale::api::user::data::Direction::Right;

// amdados_utils.cpp:
point2d_t GetGridSize(const Configuration & conf);
void ShowImage(const domain_t & state_field, int timestamp);

// scenario_sensors.cpp:
void LoadSensorLocations(const Configuration   & conf,
                         Grid<point_array_t,2> & sensors);
void LoadSensorMeasurements(const Configuration         & conf,
                            const Grid<point_array_t,2> & sensors,
                            Grid<Matrix,2>              & observations);

namespace {

const int NSIDES = 4;             // number of sides any subdomain has


/**
 * Structure keeps information about 4-side boundary of a subdomain
 * (Up, Down, Left, Right).
 */
struct Boundary
{
    double_array_t myself; // temporary storage for this subdomain boundary
    double_array_t remote; // temporary storage for remote boundary values

    double rel_diff;       // relative difference across in-flow borders
    bool   inflow[NSIDES]; // true, if flow is coming in along a side
    bool   outer[NSIDES];  // true, if side belongs to domain's outer boundary
};

typedef std::pair<double,double> flow_t;    // flow components (flow_x, flow_y)



//=============================================================================
// Variables and data associated with a sub-domain.
//=============================================================================
struct SubdomainContext
{
    Matrix        field;        // sub-domain represented as a matrix
    Boundary      boundaries;   // sub-domain boundaries

    KalmanFilter  Kalman;       // Kalman filter
    Matrix        B;            // inverse model matrix

    Matrix        P;            // process model covariance
    Matrix        Q;            // process noise covariance
    Matrix        H;            // observation matrix
    Matrix        R;            // observation noise covariance
    Vector        z;            // observation vector

    point_array_t   sensors;    // sensor locations at the finest resolution
    LUdecomposition LU;         // used for state propagation without sensors
    Matrix          tmp_field;  // used for state propagation without sensors

    point2d_t     idx;          // subdomain's position on the grid
    size_t        Nt;           // number of time integration steps
    size_t        Nschwarz;     // number of Schwarz iterations
    size_t        Nsensors;     // convenience variable = sensors.size()
    flow_t        flow;         // current flow vector (vel_x, vel_y)
    int           active_layer; // active level of multi-resolution

    SubdomainContext()
        : field(), boundaries()
        , Kalman(), B()
        , P(), Q(), H(), R(), z()
        , sensors(), LU(), tmp_field()
        , idx(-1,-1), Nt(0), Nschwarz(0), Nsensors(0), flow(0.0, 0.0)
        , active_layer(LayerFine) {}
};

// The whole domain where instead of grid cells we place sub-domain data.
using context_domain_t = ::allscale::api::user::data::Grid<SubdomainContext,2>;

//#############################################################################
// @Utilities.
//#############################################################################

/**
 * Function converts 2D index to a flat 1D one.
 * A T T E N T I O N:
 * (1) ordinate changes faster than abscissa; this matches with row-major
 *     Matrix class.
 * (2) the finest subdomain resolution is assumed.
 */
inline int Sub2Ind(int x, int y)
{
#ifndef NDEBUG
    if (!((static_cast<unsigned>(x) < static_cast<unsigned>(SUBDOMAIN_X)) &&
          (static_cast<unsigned>(y) < static_cast<unsigned>(SUBDOMAIN_Y))))
        assert_true(0);
#endif
    return (x * SUBDOMAIN_Y + y);
}

/**
 * Function converts 2D index to a flat 1D one given a layer size.
 * N O T E: ordinate changes faster than abscissa;
 *          this matches with row-major Matrix class.
 */
inline int Sub2IndLayer(int x, int y, const size2d_t & layer_size)
{
#ifndef NDEBUG
    if (!((static_cast<size_t>(x) < static_cast<size_t>(layer_size.x)) &&
          (static_cast<size_t>(y) < static_cast<size_t>(layer_size.y))))
        assert_true(0);
#endif
    return (x * static_cast<int>(layer_size.y) + y);
}

/**
 * Function computes: z = H * observations(t). Since H is a simple 0/1 matrix
 * that just picks up the observations at sensor locations, instead of
 * matrix-vector multiplication we get the observations directly.
 */
void GetObservations(Vector & z, const Matrix & observations, int timestep,
                     const Matrix & H, const point_array_t & sensors)
{
    const int n = static_cast<int>(observations.NCols());
    assert_true(z.Size() == n);
    for (int i = 0; i < n; ++i) { z(i) = observations(timestep, i); }

    (void) H; (void) sensors;
#ifdef AMDADOS_DEBUGGING
    #warning "Some extra validity test"
    Matrix subfield(SUBDOMAIN_X, SUBDOMAIN_Y);
    for (int i = 0; i < static_cast<int>(sensors.size()); ++i) {
        subfield(sensors[i].x, sensors[i].y) = observations(timestep, i);
    }
    Vector zz(n);
    MatVecMult(zz, H, subfield);    // z = H * observations(t)
    assert_true(std::equal(zz.begin(), zz.end(),
                            z.begin(),  z.end()));
#endif
}

//#############################################################################
// @Initialization.
//#############################################################################

/**
 * Function initializes dependent parameters given the primary ones
 * specified by user.
 */
void InitDependentParams(Configuration & conf)
{
    // Get resolution at the finest level by creating a temporary subdomain.
    subdomain_t temp;
    temp.setActiveLayer(LayerFine);
    const size2d_t layer_size = temp.getActiveLayerSize();
    const int Sx = static_cast<int>(layer_size.x);  // subdomain size x
    const int Sy = static_cast<int>(layer_size.y);  // subdomain size y

    // Check some global constants.
    static_assert((0 <= Up   ) && (Up    < NSIDES), "");
    static_assert((0 <= Down ) && (Down  < NSIDES), "");
    static_assert((0 <= Left ) && (Left  < NSIDES), "");
    static_assert((0 <= Right) && (Right < NSIDES), "");
    assert_true((Sx >= 3) && (Sy >= 3)) << "subdomain must be at least 3x3";

    // Ensure integer values for certain parameters.
    assert_true(conf.IsInteger("num_subdomains_x"));
    assert_true(conf.IsInteger("num_subdomains_y"));
    assert_true(conf.IsInteger("subdomain_x"));
    assert_true(conf.IsInteger("subdomain_y"));
    assert_true(conf.IsInteger("integration_nsteps"));

    // Check the subdomain size: hard-coded value must match the parameter.
    assert_true(conf.asInt("subdomain_x") == Sx)
                        << "subdomain_x mismatch" << std::endl;
    assert_true(conf.asInt("subdomain_y") == Sy)
                        << "subdomain_y mismatch" << std::endl;

    const point2d_t grid_size = GetGridSize(conf);
    const int nx = grid_size.x * Sx;                // global X-size
    const int ny = grid_size.y * Sy;                // global Y-size

    const double D = conf.asDouble("diffusion_coef");
    assert_true(D > 0.0);

    conf.SetInt("global_problem_size", nx * ny);
    const double dx = conf.asDouble("domain_size_x") / (nx - 1);
    const double dy = conf.asDouble("domain_size_y") / (ny - 1);
    assert_true((dx > 0) && (dy > 0));
    conf.SetDouble("dx", dx);
    conf.SetDouble("dy", dy);

    // Deduce the optimal time step from the stability criteria.
    const double dt_base = conf.asDouble("integration_period") /
                           conf.asDouble("integration_nsteps");
    const double max_vx = conf.asDouble("flow_model_max_vx");
    const double max_vy = conf.asDouble("flow_model_max_vy");
    const double dt = std::min(dt_base,
                        std::min( std::min(dx*dx, dy*dy)/(2.0*D + TINY),
                                  1.0/(std::fabs(max_vx)/dx +
                                       std::fabs(max_vy)/dy + TINY) ));
    assert_true(dt > TINY);
    conf.SetDouble("dt", dt);
    conf.SetInt("Nt", static_cast<int>(
                        std::ceil(conf.asDouble("integration_period") / dt)));
}

/**
 * Function applies Dirichlet zero boundary condition at the outer border
 * of the domain.
 */
void ApplyBoundaryCondition(domain_t & state, const point2d_t & idx)
{
    subdomain_t &  subdom = state[idx];
    const size2d_t subdom_size = subdom.getActiveLayerSize();

    const long Nx = state.size().x, Sx = subdom_size.x;
    const long Ny = state.size().y, Sy = subdom_size.y;

    // Set the leftmost and rightmost.
    if (idx.x == 0)      subdom.setBoundary(Left,  double_array_t(Sy, 0.0));
    if (idx.x == Nx - 1) subdom.setBoundary(Right, double_array_t(Sy, 0.0));

    // Set the bottommost and topmost.
    if (idx.y == 0)      subdom.setBoundary(Down, double_array_t(Sx, 0.0));
    if (idx.y == Ny - 1) subdom.setBoundary(Up,   double_array_t(Sx, 0.0));
}

//#############################################################################
// @Kalman filter stuff.
//#############################################################################

/**
 * Function computes the initial process model covariance matrix P
 * based on exponential distance.
 * TODO: better initial correlation radius
 */
void InitialCovar(const Configuration & conf, Matrix & P)
{
    // Here we express correlation distances in logical coordinates
    // of nodal points.
    const double variance = conf.asDouble("model_ini_var");
    const double covar_radius = conf.asDouble("model_ini_covar_radius");
    const double sx = std::max(covar_radius / conf.asDouble("dx"), 1.0);
    const double sy = std::max(covar_radius / conf.asDouble("dy"), 1.0);
    const int Rx = Round(std::ceil(4.0 * sx));
    const int Ry = Round(std::ceil(4.0 * sy));
    const int Nx = conf.asInt("subdomain_x");
    const int Ny = conf.asInt("subdomain_y");
    const size2d_t finest_layer_size(Nx, Ny);

    assert_true(P.IsSquare());
    assert_true(P.NRows() == Nx * Ny);
    Fill(P, 0.0);
    for (int u = 0; u < Nx; ++u) {
    for (int v = 0; v < Ny; ++v) {
        int i = Sub2IndLayer(u,v,finest_layer_size);
        double dx = 0.0, dy = 0.0;
        for (int x = u-Rx; x <= u+Rx; ++x) { if ((0 <= x) && (x < Nx)) {
        for (int y = v-Ry; y <= v+Ry; ++y) { if ((0 <= y) && (y < Ny)) {
            int j = Sub2IndLayer(x,y,finest_layer_size);
            if (i <= j) {
                dx = (u - x) / sx;
                dy = (v - y) / sy;
                P(i,j) = P(j,i) = variance * std::exp(-0.5 * (dx*dx + dy*dy));
            }
        }}}}
    }}
}

/**
 * Function computes the process model noise covariance matrix.
 */
void ComputeQ(const Configuration & conf, Matrix & Q)
{
    std::uniform_real_distribution<double> distrib;
    std::mt19937_64 gen(RandomSeed());
    const double model_noise_Q = conf.asDouble("model_noise_Q");

    assert_true(Q.IsSquare());
    Fill(Q, 0.0);
    for (int k = 0; k < Q.NRows(); ++k) {
        Q(k,k) = 1.0 + model_noise_Q * distrib(gen);    // always >= 1
    }
}

/**
 * Function computes the measurement noise covariance matrix.
 */
void ComputeR(const Configuration & conf, Matrix & R)
{
    std::uniform_real_distribution<double> distrib;
    std::mt19937_64 gen(RandomSeed());
    const double model_noise_R = conf.asDouble("model_noise_R");

    assert_true(R.IsSquare());
    Fill(R, 0.0);
    for (int k = 0; k < R.NRows(); ++k) {
        R(k,k) = 1.0 + model_noise_R * distrib(gen);    // always >= 1
    }
}

/**
 * Function initializes the observation matrix H of size:
 * (number of sensors in subdomain) x (number of nodal points in subdomain).
 */
void ComputeH(const point_array_t & sensors, Matrix & H)
{
    if (sensors.empty()) {
        H.Clear();
        return;
    }
    assert_true(H.NRows() == static_cast<int>(sensors.size()));
    assert_true(H.NCols() == SUB_PROBLEM_SIZE);
    Fill(H, 0.0);
    for (size_t k = 0; k < sensors.size(); ++k) {
        int x = sensors[k].x;
        int y = sensors[k].y;
        H(static_cast<int>(k), Sub2Ind(x,y)) = 1.0;
    }
}

//#############################################################################
// @Advection-diffusion PDE stuff.
//#############################################################################

/**
 * Function computes flow components given a discrete time.
 * \return a pair of flow components (flow_x, flow_y).
 */
flow_t Flow(const Configuration & conf, const size_t discrete_time)
{
    const double max_vx = conf.asDouble("flow_model_max_vx");
    const double max_vy = conf.asDouble("flow_model_max_vy");
    const double t = static_cast<double>(discrete_time) / conf.asDouble("Nt");
    return flow_t( -max_vx * std::sin(0.1 * t - M_PI),
                   -max_vy * std::sin(0.2 * t - M_PI) );
}

/**
 * Function initializes inverse matrix of implicit Euler time-integrator:
 * B * x_{t+1} = x_{t}, where B = A^{-1} is the matrix returned by this
 * function. The matrix must be inverted while iterating forward in time:
 * x_{t+1} = A * x_{t}.
 * Note, the matrix we generate here is acting on a subdomain.
 * Note, the model matrix B is supposed to be a sparse one. For now, since we
 * do not have a fast utility for sparse matrix inversion, we define B as
 * a dense one with many zeros.
 */
void InverseModelMatrix(Matrix & B, const Configuration & conf,
                        const Boundary & boundary, const flow_t & flow,
                        const size2d_t layer_size, int dt_divisor = 0)
{
(void) boundary;
    const int Nx = static_cast<int>(layer_size.x);  // short-hand aliases
    const int Ny = static_cast<int>(layer_size.y);

    assert_true((B.NRows() == B.NCols()) && (B.NCols() == Nx*Ny));

    const double D  = conf.asDouble("diffusion_coef");
    const double dx = conf.asDouble("dx");
    const double dy = conf.asDouble("dy");
    const double dt = conf.asDouble("dt")/((dt_divisor > 0) ? dt_divisor : 1);

    const double rho_x = D * dt / std::pow(dx,2);
    const double rho_y = D * dt / std::pow(dy,2);

    const double v0x = 2.0 * dx / dt;
    const double v0y = 2.0 * dy / dt;

    const double vx = flow.first  / v0x;
    const double vy = flow.second / v0y;

    // This operation can be avoided in case of sparse matrix.
    Fill(B, 0.0);

    // Process the internal and boundary subdomain points separately.
    // At each border we treat outside points with finite difference scheme.
    // If there is no incoming flow, we replace missed point values (outside
    // a subdomain) by the values inside subdomain in such way that the field
    // derivative along the border normal is zero.
    for (int x = 0; x < Nx; ++x) {
    for (int y = 0; y < Ny; ++y) {
        int i = Sub2IndLayer(x,y,layer_size);

        if ((x == 0) || (x+1 == Nx) || (y == 0) || (y+1 == Ny)) { // border
            B(i,i) += 1 + 2*(rho_x + rho_y);

            if (x == 0) {
                //if (boundary.inflow[Left]) {
                    B(i,Sub2IndLayer(x  ,y,layer_size)) += - 2*vx - rho_x;
                    B(i,Sub2IndLayer(x+1,y,layer_size)) += + 2*vx - rho_x;
                //} else {
                    //B(i,Sub2IndLayer(x+1,y,layer_size)) += - vx - rho_x;
                    //B(i,Sub2IndLayer(x+1,y,layer_size)) += + vx - rho_x;
                //}
            } else if (x == Nx-1) {
                //if (boundary.inflow[Right]) {
                    B(i,Sub2IndLayer(x-1,y,layer_size)) += - 2*vx - rho_x;
                    B(i,Sub2IndLayer(x  ,y,layer_size)) += + 2*vx - rho_x;
                //} else {
                    //B(i,Sub2IndLayer(x-1,y,layer_size)) += - vx - rho_x;
                    //B(i,Sub2IndLayer(x-1,y,layer_size)) += + vx - rho_x;
                //}
            } else {
                B(i,Sub2IndLayer(x-1,y,layer_size)) += - vx - rho_x;
                B(i,Sub2IndLayer(x+1,y,layer_size)) += + vx - rho_x;
            }

            if (y == 0) {
                //if (boundary.inflow[Down]) {
                    B(i,Sub2IndLayer(x,y  ,layer_size)) += - 2*vy - rho_y;
                    B(i,Sub2IndLayer(x,y+1,layer_size)) += + 2*vy - rho_y;
                //} else {
                    //B(i,Sub2IndLayer(x,y+1,layer_size)) += - vy - rho_y;
                    //B(i,Sub2IndLayer(x,y+1,layer_size)) += + vy - rho_y;
                //}
            } else if (y == Ny-1) {
                //if (boundary.inflow[Up]) {
                    B(i,Sub2IndLayer(x,y-1,layer_size)) += - 2*vy - rho_y;
                    B(i,Sub2IndLayer(x,y  ,layer_size)) += + 2*vy - rho_y;
                //} else {
                    //B(i,Sub2IndLayer(x,y-1,layer_size)) += - vy - rho_y;
                    //B(i,Sub2IndLayer(x,y-1,layer_size)) += + vy - rho_y;
                //}
            } else {
                B(i,Sub2IndLayer(x,y-1,layer_size)) += - vy - rho_y;
                B(i,Sub2IndLayer(x,y+1,layer_size)) += + vy - rho_y;
            }
        } else {                            // internal point
            B(i,i) = 1 + 2*(rho_x + rho_y);
            B(i,Sub2IndLayer(x-1,y,layer_size)) = - vx - rho_x;
            B(i,Sub2IndLayer(x+1,y,layer_size)) = + vx - rho_x;
            B(i,Sub2IndLayer(x,y-1,layer_size)) = - vy - rho_y;
            B(i,Sub2IndLayer(x,y+1,layer_size)) = + vy - rho_y;
        }
    }}
}

/**
 * Function implements the idea of Schwarz method where the boundary values
 * of subdomain are get updated depending on flow direction.
 */
double SchwarzUpdate(const Configuration & conf,
                     Boundary            & border,
                     const point2d_t     & idx,
                     const domain_t      & curr_domain,
                     domain_t            & next_domain,
                     const flow_t        & flow)
{
    // Subdomain and its sizes.
    const subdomain_t & subdomain = curr_domain[idx];
    const long Sx = const_cast<subdomain_t&>(
                                        subdomain).getActiveLayerSize().x;
    const long Sy = const_cast<subdomain_t&>(
                                        subdomain).getActiveLayerSize().y;
    (void) Sx; (void) Sy;

    // Origin and the number of subdomains in both directions.
    const long Ox = 0, Nx = curr_domain.size().x;
    const long Oy = 0, Ny = curr_domain.size().y;
    assert_true(curr_domain.size() == next_domain.size());

    // Index increments and corresponding directions
    // of a neighbour subdomain (remote peer).
    Direction remote_dir[NSIDES];
    point2d_t remote_idx[NSIDES];

    // Given index and position of a subdomain boundary, we use lookup tables
    // to access the neighbour subdomain (remote peer).
    remote_dir[Left ] = Right;  remote_idx[Left ] = point2d_t{-1,0};
    remote_dir[Right] = Left;   remote_idx[Right] = point2d_t{+1,0};
    remote_dir[Down ] = Up;     remote_idx[Down ] = point2d_t{0,-1};
    remote_dir[Up   ] = Down;   remote_idx[Up   ] = point2d_t{0,+1};

    const double D = conf.asDouble("diffusion_coef");

    // Function updates a boundary depending on flow direction and accumulates
    // the difference between this and peer subdomain using Schwarz method.
    auto UpdBoundary = [&](Direction dir, bool is_outer, const point2d_t & idx,
                           double & numer_sum, double & denom_sum)
    {
        border.outer[dir] = is_outer;
        border.inflow[dir] = false;
        if (is_outer) return;       // no incoming flow on outer border

        // Make a normal vector pointing outside the subdomain.
        const int normal_x = (dir == Right) ? +1 : ((dir == Left) ? -1 : 0);
        const int normal_y = (dir ==    Up) ? +1 : ((dir == Down) ? -1 : 0);

        // Compute gradient to estimate diffusion flux. Note, the normal vector
        // (which will multiply this gradient later on) always has one zero
        // component. So, depending on orientation, we compute only one gradient
        // component since the other one will be multiplied by zero in any case.
        double grad_x = 0.0, grad_y = 0.0;
#if 0
        switch (dir) {
            case Left: {
                for (long y = 0; y < Sy; ++y) {
                    grad_x += subdomain[{1,y}] - subdomain[{0,y}];
                }
                grad_x /= double(Sy);   // mean gradient on that side
            }
            break;
            case Right: {
                for (long y = 0; y < Sy; ++y) {
                    grad_x += subdomain[{Sx-1,y}] - subdomain[{Sx-2,y}];
                }
                grad_x /= double(Sy);   // mean gradient on that side
            }
            break;
            case Down: {
                for (long x = 0; x < Sx; ++x) {
                    grad_y += subdomain[{x,1}] - subdomain[{x,0}];
                }
                grad_y /= double(Sx);   // mean gradient on that side
            }
            break;
            case Up: {
                for (long x = 0; x < Sx; ++x) {
                    grad_y += subdomain[{x,Sy-1}] - subdomain[{x,Sy-2}];
                }
                grad_y /= double(Sx);   // mean gradient on that side
            }
            break;
        }
#endif
        const double flux_x = flow.first  - D * grad_x;
        const double flux_y = flow.second - D * grad_y;

        // Update the boundary points if flow enters the subdomain.
        if (normal_x * flux_x + normal_y * flux_y < 0) {
            Direction peer_dir = remote_dir[dir];
            point2d_t peer_idx = remote_idx[dir] + idx;
            assert_true((0 <= peer_idx.x) && (peer_idx.x < Nx));
            assert_true((0 <= peer_idx.y) && (peer_idx.y < Ny));

            // Copy values from peer's boundary to this subdomain boundary.
            border.inflow[dir] = true;          // in-flow boundary
#ifdef AMDADOS_DEBUGGING
            border.myself = next_domain[idx].getBoundary(dir);
#endif
            border.remote = curr_domain[peer_idx].getBoundary(peer_dir);
            next_domain[idx].setBoundary(dir, border.remote);

#ifdef AMDADOS_DEBUGGING
            // Compute and accumulate aggregated difference between
            // boundary values of this subdomain before and after update.
            double rsum = 0.0, msum = 0.0, diff = 0.0;
            assert_true(border.myself.size() == border.remote.size());
            for (size_t k = 0, n = border.remote.size(); k < n; ++k) {
                diff += std::fabs(border.remote[k] - border.myself[k]);
                rsum += std::fabs(border.remote[k]);
                msum += std::fabs(border.myself[k]);
            }
            numer_sum += diff;
            denom_sum += std::max(rsum, msum);
#endif
        }
    };

    // Update subdomain boundaries.
    double numer_sum = 0.0, denom_sum = 0.0;

    UpdBoundary(Left,  (idx.x == Ox),     idx, numer_sum, denom_sum);
    UpdBoundary(Right, (idx.x == Nx - 1), idx, numer_sum, denom_sum);
    UpdBoundary(Down,  (idx.y == Oy),     idx, numer_sum, denom_sum);
    UpdBoundary(Up,    (idx.y == Ny - 1), idx, numer_sum, denom_sum);

    border.rel_diff = numer_sum / std::max(denom_sum, TINY);
    return border.rel_diff;
}

/**
 * Copy matrix from Allscale matrix. TODO: can be faster.
 */
void MatrixFromAllscale(Matrix & m, const subdomain_t & a)
{
    // TODO: we need casting since getActiveLayerSize is mistakenly non-const.
    const size2d_t sz = const_cast<subdomain_t&>(a).getActiveLayerSize();
    const int nrows = sz[0];
    const int ncols = sz[1];
    assert_true((m.NRows() == nrows) && (m.NCols() == ncols));
    for (int r = 0; r < nrows; ++r) {
    for (int c = 0; c < ncols; ++c) { m(r,c) = a[{r,c}]; }}
}

/**
 * Copy Allscale matrix from matrix. TODO: can be faster.
 */
void AllscaleFromMatrix(subdomain_t & a, const Matrix & m)
{
    const size2d_t sz = a.getActiveLayerSize();
    const int nrows = sz[0];
    const int ncols = sz[1];
    assert_true((m.NRows() == nrows) && (m.NCols() == ncols));
    for (int r = 0; r < nrows; ++r) {
    for (int c = 0; c < ncols; ++c) { a[{r,c}] = m(r,c); }}
}

/**
 * Function is invoked for each sub-domain during the time integration.
 */
const subdomain_t & SubdomainRoutine(
                            const Configuration & conf,
                            const point_array_t & sensors,
                            const Matrix        & observations,
                            const bool            external,
                            const size_t          timestamp,
                            const domain_t      & curr_state,
                            domain_t            & next_state,
                            SubdomainContext    & ctx,
                            AverageProfile      & diff_profile)
{
    assert_true(&curr_state != &next_state);
    assert_true(curr_state.size() == next_state.size());

    // Index (position) of the current subdomain.
    const point2d_t idx = ctx.idx;

    // Important: synchronize active layers, otherwise when we exchange data
    // at the borders of neighbour subdomains the size mismatch can happen.
    next_state[idx].setActiveLayer(curr_state[idx].getActiveLayer());

    // Get the discrete time (index of iteration) in the range [0..Nt) and
    // the index of Schwarz sub-iteration in the range [0..Nschwarz).
    assert_true(timestamp < ctx.Nt * ctx.Nschwarz);
    const size_t t_discrete = timestamp / ctx.Nschwarz;
    const size_t sub_iter   = timestamp % ctx.Nschwarz;

    // At the beginning of a regular iteration (i.e. at the first Schwarz
    // sub-iteration) do: (1) update the flow velocity, (2) get the new
    // observations; (3) obtain new noise covariance matrices; (4) compute
    // the prior estimation of the state field.
    if (sub_iter == 0) {
        if (idx == point2d_t(0,0)) MY_PROGRESS("+")

        // Compute flow velocity vector.
        ctx.flow = Flow(conf, t_discrete);

        // Get the current sensor measurements.
        GetObservations(ctx.z, observations, t_discrete, ctx.H, sensors);

        // Covariance matrices are allowed to change over time.
        ComputeQ(conf, ctx.Q);
        ComputeR(conf, ctx.R);

        // Copy state field into the matrix object.
        MatrixFromAllscale(ctx.field, curr_state[idx]);

        // Prior estimation. XXX API typo: getActiveLayerSize() is non-const.
        InverseModelMatrix(ctx.B, conf, ctx.boundaries, ctx.flow,
          const_cast<subdomain_t&>(curr_state[idx]).getActiveLayerSize());
        ctx.Kalman.PropagateStateInverse(ctx.field, ctx.P, ctx.B, ctx.Q);

        // Put the prior estimation back to the state field.
        AllscaleFromMatrix(next_state[idx], ctx.field);

        // Ensure boundary conditions on the outer border.
        if (external) {
            ApplyBoundaryCondition(next_state, idx);
        }
    } else {
        if (idx == point2d_t(0,0)) MY_PROGRESS(".")
    }

    // Update subdomain boundaries according to Schwarz method.
    double diff = SchwarzUpdate(conf, ctx.boundaries, idx,
                                curr_state, next_state, ctx.flow);

    // Ensure boundary conditions on the outer border.
    if (external) {
        ApplyBoundaryCondition(next_state, idx);
    }

    // Accumulate history of discrepancies for debugging,
    diff_profile.Accumulate(idx, diff);

    // Copy state field into more convenient matrix object.
    MatrixFromAllscale(ctx.field, next_state[idx]);

    // Filtering by Kalman filter.
    ctx.Kalman.SolveFilter(ctx.field, ctx.P, ctx.H, ctx.R, ctx.z);

    // Put new estimation back to the state field.
    AllscaleFromMatrix(next_state[idx], ctx.field);

    // Ensure boundary conditions on the outer border.
    if (external) {
        ApplyBoundaryCondition(next_state, idx);
    }

    // Ensure non-negative (physically plausible) density.
    next_state[idx].forAllActiveNodes([](double & v){ if (v < 0.0) v = 0.0; });
    return next_state[idx];
}

/**
 * Function is invoked for each sub-domain during the time integration.
 */
const subdomain_t & SubdomainRoutineNoSensors(
                            const Configuration & conf,
                            const bool            external,
                            const size_t          timestamp,
                            const domain_t      & curr_state,
                            domain_t            & next_state,
                            SubdomainContext    & ctx,
                            AverageProfile      & diff_profile)
{
    assert_true(&curr_state != &next_state);
    assert_true(curr_state.size() == next_state.size());

    // Index (position) of the current subdomain.
    const point2d_t idx = ctx.idx;

    // Important: synchronize active layers, otherwise when we exchange data
    // at the borders of neighbour subdomains the size mismatch can happen.
    next_state[idx].setActiveLayer(curr_state[idx].getActiveLayer());

    // Get the discrete time (index of iteration) in the range [0..Nt) and
    // the index of Schwarz sub-iteration in the range [0..Nschwarz).
    assert_true(timestamp < ctx.Nt * ctx.Nschwarz);
    const size_t t_discrete = timestamp / ctx.Nschwarz;
    const size_t sub_iter   = timestamp % ctx.Nschwarz;

    if (idx == point2d_t(0,0)) MY_PROGRESS((sub_iter == 0) ? "+" : ".")

    // Compute flow velocity vector.
    ctx.flow = Flow(conf, t_discrete);

    // Copy state field into the matrix object.
    MatrixFromAllscale(ctx.field, curr_state[idx]);

    // Prior estimation. XXX API typo: getActiveLayerSize() is non-const.
    InverseModelMatrix(ctx.B, conf, ctx.boundaries, ctx.flow,
            const_cast<subdomain_t&>(curr_state[idx]).getActiveLayerSize(),
            ctx.Nschwarz);
    ctx.tmp_field = ctx.field;              // copy state into a temporary one
    ctx.LU.Init(ctx.B);                     // decompose: B = L*U
    ctx.LU.Solve(ctx.field, ctx.tmp_field); // new_field = B^{-1}*old_field

    // Put the prior estimation back to the state field.
    AllscaleFromMatrix(next_state[idx], ctx.field);

    // Update subdomain boundaries according to Schwarz method.
    double diff = SchwarzUpdate(conf, ctx.boundaries, idx,
                                curr_state, next_state, ctx.flow);

    // Ensure boundary conditions on the outer border.
    if (external) {
        ApplyBoundaryCondition(next_state, idx);
    }

    // Accumulate history of discrepancies for debugging,
    diff_profile.Accumulate(idx, diff);

    // Ensure non-negative (physically plausible) density.
    next_state[idx].forAllActiveNodes([](double & v){ if (v < 0.0) v = 0.0; });
    return next_state[idx];
}

/**
 * Using model matrix A, the function integrates advection-diffusion equation
 * forward in time inside individual subdomains and records all the solutions
 * as the state fields. Schwarz iterations are applied in order to make the
 * global solution seamless along subdomain boundaries. On top of that, the
 * Kalman filters (separate filter in each subdomain) drive the solution
 * towards the observations at sensor locations (data assimilation).
 */
void RunDataAssimilation(const Configuration         & conf,
                         const Grid<point_array_t,2> & sensors,
                         const Grid<Matrix,2>        & observations)
{
    using ::allscale::api::core::FileIOManager;
    using ::allscale::api::core::Entry;
    using ::allscale::api::core::Mode;

    MY_INFO("%s", "Running simulation with data assimilation")

	//Visualizer	   vis(conf.asString("output_dir"));
    AverageProfile diff_profile(conf);

    const point2d_t GridSize = GetGridSize(conf);   // size in subdomains
    const size_t    Nt = conf.asUInt("Nt");
    const size_t    Nschwarz = conf.asUInt("schwarz_num_iters");
    const size_t    Nwrite = conf.asUInt("write_num_fields");

    // Visualization: image of the sensor positions in the whole domain.
//XXX    vis.WriteImageOfSensors(H);

    context_domain_t contexts(GridSize);    // variables of each sub-domain
    domain_t         temp_field(GridSize);  // grid if sub-domains
    domain_t         state_field(GridSize); // grid if sub-domains

    // Initialize the observation and model covariance matrices.
    pfor(point2d_t(0,0), GridSize, [&](const point2d_t & idx) {
        // Important: the finest level elsewhere at the beginning.
        state_field[idx].setActiveLayer(LayerFine);
        temp_field[idx].setActiveLayer(LayerFine);

        // Zero field at the beginning.
        state_field[idx].forAllActiveNodes([](double & v) { v = 0.0; });
        ApplyBoundaryCondition(state_field, idx);

        const int Nsensors = static_cast<int>(sensors[idx].size());
        const size2d_t layer_size = state_field[idx].getActiveLayerSize();
        const int Sx = static_cast<int>(layer_size.x);
        const int Sy = static_cast<int>(layer_size.y);
        const int sub_prob_size = Sx * Sy;

        SubdomainContext & ctx = contexts[idx];
        ctx.field.Resize(Sx, Sy);
        ctx.B.Resize(sub_prob_size, sub_prob_size);
        ctx.P.Resize(sub_prob_size, sub_prob_size);
        ctx.Q.Resize(sub_prob_size, sub_prob_size);
        ctx.H.Resize(Nsensors, sub_prob_size);
        ctx.R.Resize(Nsensors, Nsensors);
        ctx.z.Resize(Nsensors);
        ctx.sensors = sensors[idx];
        ctx.idx = idx;
        ctx.Nt = Nt;
        ctx.Nschwarz = Nschwarz;
        ctx.Nsensors = sensors[idx].size();
        ComputeH(sensors[idx], ctx.H);
        InitialCovar(conf, ctx.P);
    });

    // Open file manager and the output file for writing.
    std::string filename = MakeFileName(conf, "field");
    FileIOManager & file_manager = FileIOManager::getInstance();
    Entry stream_entry = file_manager.createEntry(filename, Mode::Binary);
    auto out_stream = file_manager.openOutputStream(stream_entry);

    // Time integration forward in time. We want to make Nt (normal) iterations
    // and Nschwarz Schwarz sub-iterations within each (normal) iteration.
    ::allscale::api::user::algorithm::stencil(
        state_field, Nt * Nschwarz,
        // Process the internal subdomains.
        [&](time_t t, const point2d_t & idx, const domain_t & state)
        -> const subdomain_t &  // cell is not copy-constructible, so '&'
        {
            assert_true(t >= 0);
            if (contexts[idx].Nsensors > 0) {
                return SubdomainRoutine(conf, sensors[idx], observations[idx],
                                        false, size_t(t), state, temp_field,
                                        contexts[idx], diff_profile);
            } else {
                return SubdomainRoutineNoSensors(conf, false, size_t(t),
                            state, temp_field, contexts[idx], diff_profile);
            }
        },
        // Process the external subdomains.
        [&](time_t t, const point2d_t & idx, const domain_t & state)
        -> const subdomain_t &  // cell is not copy-constructible, so '&'
        {
            if (idx == point2d_t(0,0)) {
                ShowImage(state, static_cast<int>(t / (5 * time_t(Nschwarz))));
            }

            if (contexts[idx].Nsensors > 0) {
                return SubdomainRoutine(conf, sensors[idx], observations[idx],
                                        true, size_t(t), state, temp_field,
                                        contexts[idx], diff_profile);
            } else {
                return SubdomainRoutineNoSensors(conf, true, size_t(t),
                            state, temp_field, contexts[idx], diff_profile);
            }
        },
        // Monitoring.
        ::allscale::api::user::algorithm::observer(
            // Time filter: choose few moments evenly distributed on time axis.
            [=](time_t t) {
                // Filter out the first Schwarz sub-iteration, skip the others.
                if ((t % time_t(Nschwarz)) != 0)
                    return false;
                t /= time_t(Nschwarz);
                return ((((Nwrite-1)*(t-1))/(Nt-1) != ((Nwrite-1)*t)/(Nt-1)));
            },
            // Space filter: no specific points.
            [](const point2d_t &) { return true; },
            // Append a full field to the file of simulation results.
            [&](time_t t, const point2d_t & idx, const subdomain_t & cell) {
                t /= time_t(Nschwarz);
                // Important: here we operate at the finest level only.
                subdomain_t temp;
                temp = cell;
                while (temp.getActiveLayer() != LayerFine) {
                    temp.refine([](const double & elem) { return elem; });
                }
                const size2d_t finest_layer_size = temp.getActiveLayerSize();
                // Write the subdomain into file.
                temp.forAllActiveNodes([&](const point2d_t & loc, double val) {
                    point2d_t glo = Sub2Glo(loc, idx, finest_layer_size);
                    out_stream.atomic([=](auto & file) {
                        file.write(static_cast<float>(t));
                        file.write(static_cast<float>(glo.x));
                        file.write(static_cast<float>(glo.y));
                        file.write(static_cast<float>(val));
                    });
                });
            }
        )
    );
    file_manager.close(out_stream);
    diff_profile.PrintProfile(conf, "schwarz_diff");
    MY_INFO("%s", "\n\n")
}

} // anonymous namespace

/**
 * The main function of this application runs simulation with data
 * assimilation using Schwarz method to handle domain subdivision.
 */
void ScenarioSimulation(const std::string & config_file)
{
    MY_INFO("%s", "***** Amdados2D application *****")
    MY_INFO("%s", "AMDADOS_DEBUGGING is enabled")

    // Read application parameters from configuration file,
    // prepare the output directory.
    Configuration conf;
    conf.ReadConfigFile(config_file);
    InitDependentParams(conf);
    conf.PrintParameters();
    //CleanOutputDir(conf.asString("output_dir"));

    // Load sensor data obtained from Python code.
    Grid<point_array_t,2> sensors(GetGridSize(conf));
    Grid<Matrix,2> observations(GetGridSize(conf));
    LoadSensorLocations(conf, sensors);
    LoadSensorMeasurements(conf, sensors, observations);

    // Run the simulation with data assimilation. Important: by this time
    // some parameters had been initialized in InitDependentParams(..), so
    // we can safely proceed to the main part of the simulation algorithm.
    RunDataAssimilation(conf, sensors, observations);

    //MakeVideo(conf, "field");
}

} // namespace amdados
